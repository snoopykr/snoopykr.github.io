---
layout: single
title: "하이퍼파라미터"
categories : AI
tag: [hyperopt, ML, Optuna, TIL]
---

Hyperparameter 연구중...!!!

## Hyperparameter vs. Parameter

||Hyperparameter|Parameter|
|--|--|--|
|설명|초매개변수<br>모델 학습 과정에 반영되는 값<br>학습 시작 전에 미리 조정	매개변수|매개변수<br>모델 내부에서 결정되는 변수<br>데이터로부터 학습 또는 예측되는 값|
|예시|학습률<br>손실 함수<br>배치 사이즈|정규분포의 평균, 표준편차<br>선형 회귀 계수<br>가중치, 편향|
|직접 조정 가능|O|X|

## 하이퍼파라미터의 종류
- 학습률
- 은닉층 개수
- 배치 사이즈
- 모멘텀
- 에폭 횟수
- 손실 함수 종류
- knn의 k값

이외에도 SVM의 C와 감마, 랜덤포레스트의 가지 개수 등 모델에서 우리가 직접 설정해야 하는 변수들을 통칭해 '하이퍼파라미터'라고 한다.

## 하이퍼파라미터 튜닝의 종류

- Manual Search
- Grid Search
- Random Search
- Bayesian Optimization
- Non-Probabilistic
- Evolutionary Optimization
- Gradient-based Optimization
- Early Stopping

이 중 manual을 제외한 나머지 방법을 'automated hyperparameter selection'이라 부른다.

## Optuna

https://optuna.org/

Optuna란 하이퍼파라미터 최적화 태스크를 자동화해주는 프레임워크로, 다음과 같은 장점이 있다.

- 거의 모든 ML/DL 프레임워크에서 사용 가능한 넓은 범용성을 가지고 있다.
- 간단하고 빠르다.
- 최신 동향의 다양한 최적화 알고리즘을 갖추고 있다.
- 병렬 처리가 가능하다.
- 간단한 메소드로 시각화가 가능하다.

이러한 이유로 하이퍼파라미터 튜닝 자동화 프레임워크인 HyperOpt와 비교했을 때 비교적 많이 쓰이고 있다.

Optuna를 이해하기 위해서는 다음의 용어에 익숙해져야 한다.

- Study: 목적 함수에 기반한 최적화
- Trial: 목적함수 시행

쉽게 말해 study는 최적화를 하는 과정이고, trial은 다양한 조합으로 목적함수를 시행하는 횟수를 뜻한다.

Study의 목적은 여러 번의 trial을 거쳐 최적의 하이퍼파라미터 조합을 찾는 것이라고 할 수 있겠다.

## HyperOpt

https://hyperopt.github.io/hyperopt/

HyperOpt는 베이지안 최적화의 접근 방식을 취한다.

베이시안 최적화는 objective function(목적 함수)를 최대/최소로 하는 최적해를 찾는 기법이다.

목적함수와 하이퍼파라미터의 Pair를 대상으로 Surrogate Model을 만들어 평가하면서 순차적으로 업데이트 하면서 최적의 조합을 찾아낸다.

HyperOpt는 자동화된 하이퍼파라미터 튜닝 프레임워크로서, fmin()이라는 함수 안에는 3가지의 파라미터가 있다:

- Objective Function: 최소화할 손실 함수
- Domain Space: 탐색 범위. 베이지안 최적화에서는 이 범위가 각 하이퍼파라미터에 대해 통계 분포를 만들어낸다.
- Optimization Algorithm : 최적의 조합을 찾기 위한 알고리즘

## 참조

https://neptune.ai/blog/optuna-vs-hyperopt

https://ichi.pro/ko/hyperopt-beijian-choejeoghwaleul-giban-eulo-han-haipeo-palamiteo-tyuning-140338828128041

https://velog.io/@emseoyk/%ED%95%98%EC%9D%B4%ED%8D%BC%ED%8C%8C%EB%9D%BC%EB%AF%B8%ED%84%B0-%ED%8A%9C%EB%8B%9D

https://shinminyong.tistory.com/37
